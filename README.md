# Emotion Recognition with Multi-modal data using AI techniques
## Overview
Identifying emotion from speech is a non-trivial task pertaining to the ambiguous definition of emotion itself. In this work, we build light-weight multimodal machine learning models and compare it against the heavier and less interpretable deep learning counterparts. Our experiments show that the light-weight models are comparable to the deep learning baselines and even outperform them in some cases, achieving state-of-the-art performance on the IEMOCAP dataset.
The dataset is used to train two types of models:

ML-based: Logistic Regression and Random Forest.
DL-based: LSTM Classifier, CNN and Transfomer.

This project was conducted with significant guidance from prior research and insights drawn from various peer-reviewed research papers particularly from -"MULTIMODAL SPEECH EMOTION RECOGNITION AND AMBIGUITY RESOLUTION", by GAURAV SAHU 
which provided a strong theoretical and methodological foundation for the work.
For a more detailed explanation, please check the report.
